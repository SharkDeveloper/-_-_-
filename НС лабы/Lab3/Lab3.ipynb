{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Скачивание файлов"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa3e7bd8389adec9"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:56:42.783947300Z",
     "start_time": "2024-05-23T15:56:42.727601500Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://www.dropbox.com/s/bbm6rxqb4bsfl2d/training_data.xlsx\n",
    "!wget https://www.dropbox.com/s/gjhur7eyzcv265y/test_data.xlsx"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "чтение файлов"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "33dd7136525f02a1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Чтение данных из файлов Excel\n",
    "training_data = pd.read_excel('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/НС лабы/Lab3/training_data.xlsx',usecols=lambda x: 'Unnamed' not in x, na_values=[''], keep_default_na=False)\n",
    "test_data     = pd.read_excel('D:/Valerian/Documents/OneDrive/Python/ДопОбр Анализ данных/НС лабы/Lab3/test_data.xlsx',usecols=lambda x: 'Unnamed' not in x, na_values=[''], keep_default_na=False)\n",
    "# Заменяем NaN на '0'\n",
    "training_data = training_data.fillna(\"0\")\n",
    "test_data = test_data.fillna(\"0\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:56:53.765764400Z",
     "start_time": "2024-05-23T15:56:50.853793400Z"
    }
   },
   "id": "9d8904bce5dda8a5",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "Подготовка данных"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "885e5394e6450c55"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Определение категориальных и числовых признаков\n",
    "categorical_features = [ 5, 6, 7, 8]\n",
    "numerical_features = [1, 2, 3, 4, 9,  10, 11,12]\n",
    "\n",
    "def data_preparation(data):\n",
    "    # Кодирование категориальных признаков\n",
    "    def one_hot_encode(data, categorical_features):\n",
    "        categories = [list(set([row[i] for row in data])) for i in categorical_features]\n",
    "        encoded_data = []\n",
    "        for row in data:\n",
    "            encoded_row = []\n",
    "            for i, feature in enumerate(row):\n",
    "                if i in categorical_features:\n",
    "                    one_hot = [0] * len(categories[categorical_features.index(i)])\n",
    "                    one_hot[categories[categorical_features.index(i)].index(feature)] = 1\n",
    "                    encoded_row.extend(one_hot)\n",
    "                else:\n",
    "                    encoded_row.append(feature)\n",
    "            encoded_data.append(encoded_row)\n",
    "        return np.array(encoded_data)\n",
    "\n",
    "    encoded_data = one_hot_encode(data, categorical_features)\n",
    "\n",
    "    # Разделение данных на признаки (X) и целевую переменную (y)\n",
    "    X = np.array(encoded_data[:, 1:],dtype=float)\n",
    "    Y = np.array(encoded_data[:, 0],dtype=float)\n",
    "\n",
    "\n",
    "    # Нормализация числовых признаков\n",
    "    for feature in numerical_features:\n",
    "        idx = feature - 2  # сдвиг из-за удаления 'price' в X\n",
    "        mean = np.mean(X[:, idx].astype(float))\n",
    "        std = np.std(X[:, idx].astype(float))\n",
    "        X[:, idx] = (X[:, idx].astype(float) - mean) / std\n",
    "\n",
    "    # Разделение данных на тренировочную и тестовую выборки\n",
    "    def train_test_split(X, y, test_size=0.2):\n",
    "        indices = np.random.permutation(X.shape[0])\n",
    "        test_size = int(X.shape[0] * test_size)\n",
    "        test_indices = indices[:test_size]\n",
    "        train_indices = indices[test_size:]\n",
    "        return X[train_indices], X[test_indices], y[train_indices], y[test_indices]\n",
    "    return X,Y\n",
    "\n",
    "X_train, Y_train = data_preparation(training_data.values.tolist())\n",
    "X_test, Y_test  = data_preparation(test_data.values.tolist())\n",
    "# Добавление нового столбца к X_test\n",
    "# Например, новый столбец с постоянным значением 1\n",
    "new_column = np.ones((X_test.shape[0], 1))\n",
    "\n",
    "# Добавление нового столбца к X_test\n",
    "X_test = np.hstack((X_test, new_column))\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:57:56.610905900Z",
     "start_time": "2024-05-23T15:57:56.121600300Z"
    }
   },
   "id": "92991c6fd8b6b04f",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Определене модели НС"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c627aa14f7bd6653"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_layer_sizes, output_size):\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        layer_sizes = [input_size] + hidden_layer_sizes + [output_size]\n",
    "        for i in range(len(layer_sizes) - 1):\n",
    "            self.weights.append(np.random.randn(layer_sizes[i], layer_sizes[i + 1]))\n",
    "            self.biases.append(np.zeros((1, layer_sizes[i + 1])))\n",
    "\n",
    "    def relu(self, x):\n",
    "        return np.maximum(0, x)\n",
    "\n",
    "    def relu_derivative(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "\n",
    "    def forward(self, X):\n",
    "        activations = [X]\n",
    "        for i in range(len(self.weights)):\n",
    "            z = activations[-1].dot(self.weights[i]) + self.biases[i]\n",
    "            a = self.relu(z) if i < len(self.weights) - 1 else z  # Linear activation in output layer\n",
    "            activations.append(a)\n",
    "\n",
    "        return activations\n",
    "\n",
    "    def backward(self, activations, y, learning_rate):\n",
    "        m = y.shape[0]\n",
    "        deltas = [activations[-1] - y.reshape(-1, 1)]\n",
    "        for i in range(len(self.weights) - 1, 0, -1):\n",
    "            deltas.append(deltas[-1].dot(self.weights[i].T) * self.relu_derivative(activations[i]))\n",
    "        deltas.reverse()\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] -= learning_rate * activations[i].T.dot(deltas[i]) / m\n",
    "            self.biases[i] -= learning_rate * np.sum(deltas[i], axis=0, keepdims=True) / m\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        for epoch in range(epochs):\n",
    "            activations = self.forward(X)\n",
    "            self.backward(activations, y, learning_rate)\n",
    "            if epoch % 100 == 0:\n",
    "                loss = np.mean((activations[-1] - y.reshape(-1, 1)) ** 2)\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X)[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:57:59.991097600Z",
     "start_time": "2024-05-23T15:57:59.978504400Z"
    }
   },
   "id": "8bd95ad92fbddd",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "Иницилизация и обучение модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e45e343eb10886c3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 42899546014645.66\n",
      "Epoch 100, Loss: 2.010125445712188e+169\n",
      "Epoch 200, Loss: 2.6931595364023474e+168\n",
      "Epoch 300, Loss: 3.6082863902780645e+167\n",
      "Epoch 400, Loss: 4.834370373638645e+166\n",
      "Epoch 500, Loss: 6.4770737080306896e+165\n",
      "Epoch 600, Loss: 8.677962294330056e+164\n",
      "Epoch 700, Loss: 1.1626705666239927e+164\n",
      "Epoch 800, Loss: 1.5577422448320493e+163\n",
      "Epoch 900, Loss: 2.0870579947510973e+162\n"
     ]
    }
   ],
   "source": [
    "input_size = X_train.shape[1]\n",
    "hidden_layer_sizes = [64, 32]\n",
    "output_size = 1\n",
    "\n",
    "nn = NeuralNetwork(input_size, hidden_layer_sizes, output_size)\n",
    "nn.train(X_train, Y_train, epochs=1000, learning_rate=0.01)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:58:57.616897500Z",
     "start_time": "2024-05-23T15:58:41.923693800Z"
    }
   },
   "id": "4bd7b9456aba951c",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Оценивание модели"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c35d5f3781c04da6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MAE: 5.287942431101739e+80\n",
      "Test MSE: 2.7962335154646186e+161\n"
     ]
    }
   ],
   "source": [
    "Y_pred = nn.predict(X_test)\n",
    "\n",
    "mae = np.mean(np.abs(Y_pred - Y_test.reshape(-1, 1)))\n",
    "mse = np.mean((Y_pred - Y_test.reshape(-1, 1)) ** 2)\n",
    "\n",
    "print(f'Test MAE: {mae}')\n",
    "print(f'Test MSE: {mse}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T15:59:03.956796200Z",
     "start_time": "2024-05-23T15:59:03.939116Z"
    }
   },
   "id": "488b0f9a8e157771",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d7457054fa47f082"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
